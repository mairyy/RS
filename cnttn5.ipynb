{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \ndef remove_folder_contents(folder):\n    for the_file in os.listdir(folder):\n        file_path = os.path.join(folder, the_file)\n        try:\n            if os.path.isfile(file_path):\n                os.unlink(file_path)\n            elif os.path.isdir(file_path):\n                remove_folder_contents(file_path)\n                os.rmdir(file_path)\n        except Exception as e:\n            print(e)\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-23T03:31:20.213296Z","iopub.execute_input":"2024-04-23T03:31:20.213593Z","iopub.status.idle":"2024-04-23T03:31:21.028019Z","shell.execute_reply.started":"2024-04-23T03:31:20.213568Z","shell.execute_reply":"2024-04-23T03:31:21.027292Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"secret_tokens\")\n\n!git clone https://github.com/kz-song/MMSRec.git","metadata":{"execution":{"iopub.status.busy":"2024-04-23T03:31:21.029429Z","iopub.execute_input":"2024-04-23T03:31:21.029783Z","iopub.status.idle":"2024-04-23T03:31:24.643079Z","shell.execute_reply.started":"2024-04-23T03:31:21.029759Z","shell.execute_reply":"2024-04-23T03:31:24.641968Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Cloning into 'MMSRec'...\nremote: Enumerating objects: 82, done.\u001b[K\nremote: Counting objects: 100% (82/82), done.\u001b[K\nremote: Compressing objects: 100% (62/62), done.\u001b[K\nremote: Total 82 (delta 14), reused 79 (delta 14), pack-reused 0\u001b[K\nUnpacking objects: 100% (82/82), 18.82 MiB | 10.64 MiB/s, done.\n","output_type":"stream"}]},{"cell_type":"code","source":"%cd '/kaggle/working/MMSRec'\n!sh weights/clip/download.sh\n!pip install wandb easydict pynvml torchaudio decord jsonlines transformers torchvision","metadata":{"execution":{"iopub.status.busy":"2024-04-23T03:31:24.644767Z","iopub.execute_input":"2024-04-23T03:31:24.645162Z","iopub.status.idle":"2024-04-23T03:31:57.315215Z","shell.execute_reply.started":"2024-04-23T03:31:24.645117Z","shell.execute_reply":"2024-04-23T03:31:57.314192Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/working/MMSRec\nCollecting git+https://github.com/openai/CLIP.git\n  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-ykj3x0ig\n  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-ykj3x0ig\n  Resolved https://github.com/openai/CLIP.git to commit a1d071733d7111c9c014f024669f959182114e33\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting ftfy (from clip==1.0)\n  Downloading ftfy-6.2.0-py3-none-any.whl.metadata (7.3 kB)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from clip==1.0) (2023.12.25)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from clip==1.0) (4.66.1)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from clip==1.0) (2.1.2)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from clip==1.0) (0.16.2)\nRequirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /opt/conda/lib/python3.10/site-packages (from ftfy->clip==1.0) (0.2.13)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (2024.2.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision->clip==1.0) (1.26.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision->clip==1.0) (2.31.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->clip==1.0) (9.5.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->clip==1.0) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->clip==1.0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->clip==1.0) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->clip==1.0) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->clip==1.0) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->clip==1.0) (1.3.0)\nDownloading ftfy-6.2.0-py3-none-any.whl (54 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m809.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: clip\n  Building wheel for clip (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369497 sha256=24218a15bc6edb5c4f7cd1e4bd0f22d1f0c8bbbe9acc5955ab90611fab784595\n  Stored in directory: /tmp/pip-ephem-wheel-cache-wquiapm5/wheels/da/2b/4c/d6691fa9597aac8bb85d2ac13b112deb897d5b50f5ad9a37e4\nSuccessfully built clip\nInstalling collected packages: ftfy, clip\nSuccessfully installed clip-1.0 ftfy-6.2.0\n--2024-04-23 03:31:41--  https://openaipublic.azureedge.net/clip/models/40d365715913c9da98579312b702a82c18be219cc2a73407c4526f58eba950af/ViT-B-32.pt\nResolving openaipublic.azureedge.net (openaipublic.azureedge.net)... 13.107.246.38, 13.107.213.38, 2620:1ec:bdf::38, ...\nConnecting to openaipublic.azureedge.net (openaipublic.azureedge.net)|13.107.246.38|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 353976522 (338M) [application/octet-stream]\nSaving to: './weights/clip/ViT-B-32.pt'\n\nViT-B-32.pt         100%[===================>] 337.58M   172MB/s    in 2.0s    \n\n2024-04-23 03:31:43 (172 MB/s) - './weights/clip/ViT-B-32.pt' saved [353976522/353976522]\n\nRequirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.16.6)\nRequirement already satisfied: easydict in /opt/conda/lib/python3.10/site-packages (1.13)\nRequirement already satisfied: pynvml in /opt/conda/lib/python3.10/site-packages (11.4.1)\nRequirement already satisfied: torchaudio in /opt/conda/lib/python3.10/site-packages (2.1.2)\nCollecting decord\n  Downloading decord-0.6.0-py3-none-manylinux2010_x86_64.whl.metadata (422 bytes)\nCollecting jsonlines\n  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.39.3)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.16.2)\nRequirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\nRequirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.41)\nRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.31.0)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.45.0)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0.1)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (69.0.3)\nRequirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.4.4)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from torchaudio) (2.1.2)\nRequirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from decord) (1.26.4)\nRequirement already satisfied: attrs>=19.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonlines) (23.2.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.22.2)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (9.5.0)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->torchaudio) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->torchaudio) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->torchaudio) (3.1.2)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->torchaudio) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->torchaudio) (1.3.0)\nDownloading decord-0.6.0-py3-none-manylinux2010_x86_64.whl (13.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\nInstalling collected packages: jsonlines, decord\nSuccessfully installed decord-0.6.0 jsonlines-4.0.0\n","output_type":"stream"}]},{"cell_type":"code","source":"%cd '/kaggle/working/MMSRec/dataset/amazon/raw'\n\n# Amazon All Beauty\n!mkdir Beauty\n%cd ./Beauty\n!wget --no-check-certificate http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/ratings_Beauty.csv\n!wget --no-check-certificate http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/meta_Beauty.json.gz\n%cd '/kaggle/working/MMSRec/dataset/amazon/preprocess'","metadata":{"execution":{"iopub.status.busy":"2024-04-23T03:31:57.317609Z","iopub.execute_input":"2024-04-23T03:31:57.317904Z","iopub.status.idle":"2024-04-23T03:32:05.779503Z","shell.execute_reply.started":"2024-04-23T03:31:57.317874Z","shell.execute_reply":"2024-04-23T03:32:05.778506Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"/kaggle/working/MMSRec/dataset/amazon/raw\n/kaggle/working/MMSRec/dataset/amazon/raw/Beauty\n--2024-04-23 03:31:59--  http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/ratings_Beauty.csv\nResolving snap.stanford.edu (snap.stanford.edu)... 171.64.75.80\nConnecting to snap.stanford.edu (snap.stanford.edu)|171.64.75.80|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 82432164 (79M) [text/csv]\nSaving to: 'ratings_Beauty.csv'\n\nratings_Beauty.csv  100%[===================>]  78.61M  32.0MB/s    in 2.5s    \n\n2024-04-23 03:32:01 (32.0 MB/s) - 'ratings_Beauty.csv' saved [82432164/82432164]\n\n--2024-04-23 03:32:02--  http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/meta_Beauty.json.gz\nResolving snap.stanford.edu (snap.stanford.edu)... 171.64.75.80\nConnecting to snap.stanford.edu (snap.stanford.edu)|171.64.75.80|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 99156148 (95M) [application/x-gzip]\nSaving to: 'meta_Beauty.json.gz'\n\nmeta_Beauty.json.gz 100%[===================>]  94.56M  33.1MB/s    in 2.9s    \n\n2024-04-23 03:32:05 (33.1 MB/s) - 'meta_Beauty.json.gz' saved [99156148/99156148]\n\n/kaggle/working/MMSRec/dataset/amazon/preprocess\n","output_type":"stream"}]},{"cell_type":"code","source":"!python process_item.py","metadata":{"execution":{"iopub.status.busy":"2024-04-23T03:32:05.780850Z","iopub.execute_input":"2024-04-23T03:32:05.781155Z","iopub.status.idle":"2024-04-23T03:33:54.416631Z","shell.execute_reply.started":"2024-04-23T03:32:05.781124Z","shell.execute_reply":"2024-04-23T03:33:54.415657Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"2024-04-23 03:32:15.235906: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-23 03:32:15.236030: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-23 03:32:15.360874: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n\n-----Processing data ../raw/Beauty\nload inter file ../raw/Beauty/ratings_Beauty.csv: 100%|█| 2023070/2023070 [00:05\nTotal inters: 2023070\nload meta file ../raw/Beauty/meta_Beauty.json.gz: 259204it [00:36, 7134.88it/s]\nFilter K core: user 5, item 5\n\tFilter: 2023070 inters to 394908 inters\n\tFilter: 394908 inters to 285290 inters\n\tFilter: 285290 inters to 235877 inters\n\tFilter: 235877 inters to 219260 inters\n\tFilter: 219260 inters to 208668 inters\n\tFilter: 208668 inters to 204558 inters\n\tFilter: 204558 inters to 201607 inters\n\tFilter: 201607 inters to 200447 inters\n\tFilter: 200447 inters to 199560 inters\n\tFilter: 199560 inters to 199177 inters\n\tFilter: 199177 inters to 198837 inters\n\tFilter: 198837 inters to 198713 inters\n\tFilter: 198713 inters to 198598 inters\n\tFilter: 198598 inters to 198546 inters\n\tFilter: 198546 inters to 198514 inters\n\tFilter: 198514 inters to 198506 inters\n\tFilter: 198506 inters to 198502 inters\n\tFilter: 198502 inters to 198502 inters\nfilter metas by inters: 100%|██████| 198502/198502 [00:00<00:00, 1249844.60it/s]\nProcess Item Data: 12101\n100%|███████████████████████████████████| 12101/12101 [00:02<00:00, 5493.65it/s]\nfilter metas: 100%|██████████████████| 12101/12101 [00:00<00:00, 1103495.44it/s]\nfilter inters by metas: 100%|██████| 198502/198502 [00:00<00:00, 1097381.34it/s]\nFilter K core: user 5, item 5\n\tFilter: 198502 inters to 198502 inters\ngroup inters by user: 100%|█████████| 198502/198502 [00:00<00:00, 370525.12it/s]\nProcess Seq Data: 22363\n100%|██████████████████████████████████| 22363/22363 [00:00<00:00, 36281.00it/s]\nfilter metas by inters: 100%|██████| 198502/198502 [00:00<00:00, 1253023.50it/s]\nwrite item file: 100%|████████████████| 12101/12101 [00:00<00:00, 739969.86it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"!python extract_features.py","metadata":{"execution":{"iopub.status.busy":"2024-04-23T03:33:54.418049Z","iopub.execute_input":"2024-04-23T03:33:54.418401Z","iopub.status.idle":"2024-04-23T03:35:11.283986Z","shell.execute_reply.started":"2024-04-23T03:33:54.418366Z","shell.execute_reply":"2024-04-23T03:35:11.283043Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"2024-04-23 03:33:59.904001: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-23 03:33:59.904052: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-23 03:33:59.905579: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nProcessing data ../processed/Beauty----------\n100%|█████████████████████████████████████████| 122/122 [01:02<00:00,  1.94it/s]\nwrite info: 100%|█████████████████████| 12101/12101 [00:00<00:00, 116152.76it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"%cd '/kaggle/working/MMSRec'\n!torchrun --nnodes=1:5 --nproc_per_node=1 --max_restarts=0 --rdzv_id=1 --rdzv_backend=c10d --rdzv_endpoint=\"127.0.0.1:12309\" finetune_amazon.py --config=\"/kaggle/input/fintune-beauty-config-yaml/finetune_amazon.yaml\"","metadata":{"execution":{"iopub.status.busy":"2024-04-23T03:50:20.958679Z","iopub.execute_input":"2024-04-23T03:50:20.959581Z","iopub.status.idle":"2024-04-23T05:55:36.652768Z","shell.execute_reply.started":"2024-04-23T03:50:20.959547Z","shell.execute_reply":"2024-04-23T05:55:36.651671Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"/kaggle/working/MMSRec\n[2024-04-23 03:50:23,747] torch.distributed.run: [WARNING] master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.\n04/23/2024 03:50:58 - INFO - __main__ - {'config': '/kaggle/input/fintune-beauty-config-yaml/finetune_amazon.yaml', 'wandb_enable': False, 'project_name': '', 'display_name': '', 'num_worker': 8, 'train_item_file': './dataset/amazon/processed/Beauty/item_feature.jsonl', 'train_seq_file': './dataset/amazon/processed/Beauty/train_seq.jsonl', 'eval_item_file': './dataset/amazon/processed/Beauty/item_feature.jsonl', 'eval_seq_file': './dataset/amazon/processed/Beauty/eval_seq.jsonl', 'test_item_file': './dataset/amazon/processed/Beauty/item_feature.jsonl', 'test_seq_file': './dataset/amazon/processed/Beauty/test_seq.jsonl', 'max_seq_length': 20, 'train_vision_format': 'embed', 'eval_vision_format': 'embed', 'test_vision_format': 'embed', 'max_vision_frames': 10, 'train_text_format': 'embed', 'eval_text_format': 'embed', 'test_text_format': 'embed', 'clip_model_path': './weights/clip/ViT-B-32.pt', 'vision_feature_embed_dim': 512, 'text_feature_embed_dim': 512, 'fusion_embed_dim': 512, 'fusion_layers': 2, 'fusion_heads': 8, 'fusion_feedforward_dim': 1024, 'fusion_dropout': 0.5, 'fusion_embed_dropout': 0.2, 'initializer_range': 0.02, 'seed': 42, 'log_file': './logs/finetune-amazon-2layer.log', 'train_batch_size': 1024, 'eval_batch_size': 1024, 'test_batch_size': 1024, 'num_train_epochs': 500, 'learning_rate': 0.001, 'lr_scheduler_gamma': 1.0, 'max_grad_norm': 1.0, 'contrastive_temperature': 0.05, 'ce_mask_ratio': 0.2, 'early_stopping': 10, 'model_save_path': './weights/finetune-Beauty-8192batch', 'model_resume_path': './weights/pretrain-webvid-2layer-512dim', 'rank': 0, 'local_rank': 0, 'world_size': 1, 'device': device(type='cuda', index=0)}\nDataset train items : 12101\nDataset train sequence : 131413\n/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(_create_warning_msg(\nDataset eval items : 12101\nDataset eval sequence : 22363\nDataset test items : 12101\nDataset test sequence : 22363\n04/23/2024 03:51:13 - INFO - trainer.finetune_trainer - ***** Resume Model from path ./weights/pretrain-webvid-2layer-512dim\n04/23/2024 03:51:13 - INFO - trainer.finetune_trainer - ***** Run training *****\n04/23/2024 03:51:13 - INFO - trainer.finetune_trainer -   Num examples = 131413\n04/23/2024 03:51:13 - INFO - trainer.finetune_trainer -   Num Epochs = 500\n04/23/2024 03:51:13 - INFO - trainer.finetune_trainer -   Instantaneous batch size per device = 1024\n04/23/2024 03:51:13 - INFO - trainer.finetune_trainer -   Total train batch size = 1024\n04/23/2024 03:51:13 - INFO - trainer.finetune_trainer -   Total steps = 64500\nTraining epoch 0, steps 128 : 100%|███████████| 129/129 [01:50<00:00,  1.16it/s]\n04/23/2024 03:53:04 - INFO - trainer.finetune_evaluator - ***** Run eval *****\n22it [00:05,  4.38it/s]\n04/23/2024 03:53:09 - INFO - trainer.finetune_evaluator - Epoch 0 Eval Result: R@10:0.05643250048160553, R@50:0.15065062046051025, NDCG@10:0.027321822941303253, NDCG@50:0.04752790555357933\n04/23/2024 03:53:09 - INFO - trainer.finetune_trainer - ***** Saving model checkpoint 0 to ./weights/finetune-Beauty-8192batch\nTraining epoch 1, steps 128 : 100%|███████████| 129/129 [01:52<00:00,  1.14it/s]\n04/23/2024 03:55:03 - INFO - trainer.finetune_evaluator - ***** Run eval *****\n22it [00:04,  4.48it/s]\n04/23/2024 03:55:08 - INFO - trainer.finetune_evaluator - Epoch 1 Eval Result: R@10:0.06309528648853302, R@50:0.17296425998210907, NDCG@10:0.030654041096568108, NDCG@50:0.05434441566467285\n04/23/2024 03:55:08 - INFO - trainer.finetune_trainer - ***** Saving model checkpoint 1 to ./weights/finetune-Beauty-8192batch\nTraining epoch 2, steps 128 : 100%|███████████| 129/129 [01:52<00:00,  1.14it/s]\n04/23/2024 03:57:01 - INFO - trainer.finetune_evaluator - ***** Run eval *****\n22it [00:04,  4.47it/s]\n04/23/2024 03:57:06 - INFO - trainer.finetune_evaluator - Epoch 2 Eval Result: R@10:0.06989222764968872, R@50:0.18414345383644104, NDCG@10:0.033948395401239395, NDCG@50:0.05857796221971512\n04/23/2024 03:57:06 - INFO - trainer.finetune_trainer - ***** Saving model checkpoint 2 to ./weights/finetune-Beauty-8192batch\nTraining epoch 3, steps 128 : 100%|███████████| 129/129 [01:53<00:00,  1.14it/s]\n04/23/2024 03:59:00 - INFO - trainer.finetune_evaluator - ***** Run eval *****\n22it [00:04,  4.46it/s]\n04/23/2024 03:59:05 - INFO - trainer.finetune_evaluator - Epoch 3 Eval Result: R@10:0.07843312621116638, R@50:0.19693243503570557, NDCG@10:0.03833640739321709, NDCG@50:0.06405173242092133\n04/23/2024 03:59:05 - INFO - trainer.finetune_trainer - ***** Saving model checkpoint 3 to ./weights/finetune-Beauty-8192batch\nTraining epoch 4, steps 128 : 100%|███████████| 129/129 [01:52<00:00,  1.14it/s]\n04/23/2024 04:00:58 - INFO - trainer.finetune_evaluator - ***** Run eval *****\n22it [00:04,  4.44it/s]\n04/23/2024 04:01:03 - INFO - trainer.finetune_evaluator - Epoch 4 Eval Result: R@10:0.08129499107599258, R@50:0.20261144638061523, NDCG@10:0.039464108645915985, NDCG@50:0.065678671002388\n04/23/2024 04:01:03 - INFO - trainer.finetune_trainer - ***** Saving model checkpoint 4 to ./weights/finetune-Beauty-8192batch\nTraining epoch 5, steps 128 : 100%|███████████| 129/129 [01:52<00:00,  1.14it/s]\n04/23/2024 04:02:57 - INFO - trainer.finetune_evaluator - ***** Run eval *****\n22it [00:05,  4.40it/s]\n04/23/2024 04:03:02 - INFO - trainer.finetune_evaluator - Epoch 5 Eval Result: R@10:0.08397799730300903, R@50:0.21142064034938812, NDCG@10:0.041044965386390686, NDCG@50:0.06874366849660873\n04/23/2024 04:03:02 - INFO - trainer.finetune_trainer - ***** Saving model checkpoint 5 to ./weights/finetune-Beauty-8192batch\nTraining epoch 6, steps 128 : 100%|███████████| 129/129 [01:52<00:00,  1.14it/s]\n04/23/2024 04:04:55 - INFO - trainer.finetune_evaluator - ***** Run eval *****\n22it [00:04,  4.45it/s]\n04/23/2024 04:05:00 - INFO - trainer.finetune_evaluator - Epoch 6 Eval Result: R@10:0.08666100353002548, R@50:0.21750211715698242, NDCG@10:0.042591631412506104, NDCG@50:0.07103919237852097\n04/23/2024 04:05:00 - INFO - trainer.finetune_trainer - ***** Saving model checkpoint 6 to ./weights/finetune-Beauty-8192batch\nTraining epoch 7, steps 128 : 100%|███████████| 129/129 [01:52<00:00,  1.14it/s]\n04/23/2024 04:06:54 - INFO - trainer.finetune_evaluator - ***** Run eval *****\n22it [00:05,  4.34it/s]\n04/23/2024 04:06:59 - INFO - trainer.finetune_evaluator - Epoch 7 Eval Result: R@10:0.08809193223714828, R@50:0.2170102298259735, NDCG@10:0.042109016329050064, NDCG@50:0.07013019919395447\n04/23/2024 04:06:59 - INFO - trainer.finetune_trainer - ***** Saving model checkpoint 7 to ./weights/finetune-Beauty-8192batch\nTraining epoch 8, steps 128 : 100%|███████████| 129/129 [01:52<00:00,  1.14it/s]\n04/23/2024 04:08:52 - INFO - trainer.finetune_evaluator - ***** Run eval *****\n22it [00:04,  4.41it/s]\n04/23/2024 04:08:57 - INFO - trainer.finetune_evaluator - Epoch 8 Eval Result: R@10:0.09041720628738403, R@50:0.2180834412574768, NDCG@10:0.044393494725227356, NDCG@50:0.07213693112134933\n04/23/2024 04:08:57 - INFO - trainer.finetune_trainer - ***** Saving model checkpoint 8 to ./weights/finetune-Beauty-8192batch\nTraining epoch 9, steps 128 : 100%|███████████| 129/129 [01:52<00:00,  1.14it/s]\n04/23/2024 04:10:51 - INFO - trainer.finetune_evaluator - ***** Run eval *****\n22it [00:04,  4.43it/s]\n04/23/2024 04:10:56 - INFO - trainer.finetune_evaluator - Epoch 9 Eval Result: R@10:0.09274247288703918, R@50:0.22537225484848022, NDCG@10:0.04492165520787239, NDCG@50:0.07375715672969818\n04/23/2024 04:10:56 - INFO - trainer.finetune_trainer - ***** Saving model checkpoint 9 to ./weights/finetune-Beauty-8192batch\nTraining epoch 10, steps 128 : 100%|██████████| 129/129 [01:52<00:00,  1.14it/s]\n04/23/2024 04:12:49 - INFO - trainer.finetune_evaluator - ***** Run eval *****\n22it [00:04,  4.47it/s]\n04/23/2024 04:12:54 - INFO - trainer.finetune_evaluator - Epoch 10 Eval Result: R@10:0.09318964183330536, R@50:0.22662432491779327, NDCG@10:0.04466841369867325, NDCG@50:0.0736810564994812\n04/23/2024 04:12:54 - INFO - trainer.finetune_trainer - ***** Saving model checkpoint 10 to ./weights/finetune-Beauty-8192batch\nTraining epoch 11, steps 128 : 100%|██████████| 129/129 [01:52<00:00,  1.14it/s]\n04/23/2024 04:14:48 - INFO - trainer.finetune_evaluator - ***** Run eval *****\n22it [00:04,  4.42it/s]\n04/23/2024 04:14:53 - INFO - trainer.finetune_evaluator - Epoch 11 Eval Result: R@10:0.09551490843296051, R@50:0.22622187435626984, NDCG@10:0.046312104910612106, NDCG@50:0.07459668815135956\n04/23/2024 04:14:53 - INFO - trainer.finetune_trainer - ***** Saving model checkpoint 11 to ./weights/finetune-Beauty-8192batch\nTraining epoch 12, steps 128 : 100%|██████████| 129/129 [01:52<00:00,  1.14it/s]\n04/23/2024 04:16:46 - INFO - trainer.finetune_evaluator - ***** Run eval *****\n22it [00:04,  4.47it/s]\n04/23/2024 04:16:51 - INFO - trainer.finetune_evaluator - Epoch 12 Eval Result: R@10:0.09368152171373367, R@50:0.22809998691082, NDCG@10:0.045659542083740234, NDCG@50:0.0748349204659462\nTraining epoch 13, steps 128 : 100%|██████████| 129/129 [01:52<00:00,  1.14it/s]\n04/23/2024 04:18:45 - INFO - trainer.finetune_evaluator - ***** Run eval *****\n22it [00:04,  4.42it/s]\n04/23/2024 04:18:50 - INFO - trainer.finetune_evaluator - Epoch 13 Eval Result: R@10:0.09868979454040527, R@50:0.23279523849487305, NDCG@10:0.048014651983976364, NDCG@50:0.07713586091995239\n04/23/2024 04:18:50 - INFO - trainer.finetune_trainer - ***** Saving model checkpoint 13 to ./weights/finetune-Beauty-8192batch\nTraining epoch 14, steps 128 : 100%|██████████| 129/129 [01:52<00:00,  1.14it/s]\n04/23/2024 04:20:43 - INFO - trainer.finetune_evaluator - ***** Run eval *****\n22it [00:04,  4.48it/s]\n04/23/2024 04:20:48 - INFO - trainer.finetune_evaluator - Epoch 14 Eval Result: R@10:0.0996735692024231, R@50:0.2385636866092682, NDCG@10:0.04827723652124405, NDCG@50:0.07849407196044922\n04/23/2024 04:20:48 - INFO - trainer.finetune_trainer - ***** Saving model checkpoint 14 to ./weights/finetune-Beauty-8192batch\nTraining epoch 15, steps 128 : 100%|██████████| 129/129 [01:52<00:00,  1.14it/s]\n04/23/2024 04:22:42 - INFO - trainer.finetune_evaluator - ***** Run eval *****\n22it [00:04,  4.50it/s]\n04/23/2024 04:22:47 - INFO - trainer.finetune_evaluator - Epoch 15 Eval Result: R@10:0.09640924632549286, R@50:0.23449447751045227, NDCG@10:0.047101475298404694, NDCG@50:0.07719893008470535\nTraining epoch 16, steps 128 : 100%|██████████| 129/129 [01:52<00:00,  1.14it/s]\n04/23/2024 04:24:40 - INFO - trainer.finetune_evaluator - ***** Run eval *****\n22it [00:05,  4.35it/s]\n04/23/2024 04:24:45 - INFO - trainer.finetune_evaluator - Epoch 16 Eval Result: R@10:0.10284845530986786, R@50:0.23829539120197296, NDCG@10:0.04985513910651207, NDCG@50:0.07927559316158295\n04/23/2024 04:24:45 - INFO - trainer.finetune_trainer - ***** Saving model checkpoint 16 to ./weights/finetune-Beauty-8192batch\nTraining epoch 17, steps 128 : 100%|██████████| 129/129 [01:52<00:00,  1.14it/s]\n04/23/2024 04:26:38 - INFO - trainer.finetune_evaluator - ***** Run eval *****\n22it [00:04,  4.47it/s]\n04/23/2024 04:26:44 - INFO - trainer.finetune_evaluator - Epoch 17 Eval Result: R@10:0.10168581455945969, R@50:0.23766936361789703, NDCG@10:0.0492875799536705, NDCG@50:0.078791044652462\nTraining epoch 18, steps 128 : 100%|██████████| 129/129 [01:52<00:00,  1.14it/s]\n04/23/2024 04:28:37 - INFO - trainer.finetune_evaluator - ***** Run eval *****\n22it [00:05,  4.40it/s]\n04/23/2024 04:28:42 - INFO - trainer.finetune_evaluator - Epoch 18 Eval Result: R@10:0.10226713865995407, R@50:0.2410678267478943, NDCG@10:0.049595579504966736, NDCG@50:0.07966188341379166\nTraining epoch 19, steps 128 : 100%|██████████| 129/129 [01:52<00:00,  1.14it/s]\n04/23/2024 04:30:35 - INFO - trainer.finetune_evaluator - ***** Run eval *****\n22it [00:04,  4.40it/s]\n04/23/2024 04:30:40 - INFO - trainer.finetune_evaluator - Epoch 19 Eval Result: R@10:0.10186468809843063, R@50:0.24075481295585632, NDCG@10:0.04960685223340988, NDCG@50:0.07984054833650589\nTraining epoch 20, steps 128 : 100%|██████████| 129/129 [01:52<00:00,  1.14it/s]\n04/23/2024 04:32:34 - INFO - trainer.finetune_evaluator - ***** Run eval *****\n22it [00:04,  4.45it/s]\n04/23/2024 04:32:39 - INFO - trainer.finetune_evaluator - Epoch 20 Eval Result: R@10:0.10562089085578918, R@50:0.24424271285533905, NDCG@10:0.05193034186959267, NDCG@50:0.0820108950138092\n04/23/2024 04:32:39 - INFO - trainer.finetune_trainer - ***** Saving model checkpoint 20 to ./weights/finetune-Beauty-8192batch\nTraining epoch 21, steps 128 : 100%|██████████| 129/129 [01:52<00:00,  1.14it/s]\n04/23/2024 04:34:32 - INFO - trainer.finetune_evaluator - ***** Run eval *****\n22it [00:04,  4.43it/s]\n04/23/2024 04:34:37 - INFO - trainer.finetune_evaluator - Epoch 21 Eval Result: R@10:0.10445825755596161, R@50:0.24361668527126312, NDCG@10:0.05053744837641716, NDCG@50:0.08076614141464233\nTraining epoch 22, steps 128 : 100%|██████████| 129/129 [01:52<00:00,  1.14it/s]\n04/23/2024 04:36:31 - INFO - trainer.finetune_evaluator - ***** Run eval *****\n22it [00:05,  4.37it/s]\n04/23/2024 04:36:36 - INFO - trainer.finetune_evaluator - Epoch 22 Eval Result: R@10:0.10338505357503891, R@50:0.24267762899398804, NDCG@10:0.050648342818021774, NDCG@50:0.08090750873088837\nTraining epoch 23, steps 128 : 100%|██████████| 129/129 [01:52<00:00,  1.14it/s]\n04/23/2024 04:38:29 - INFO - trainer.finetune_evaluator - ***** Run eval *****\n22it [00:04,  4.41it/s]\n04/23/2024 04:38:34 - INFO - trainer.finetune_evaluator - Epoch 23 Eval Result: R@10:0.10727541148662567, R@50:0.24710458517074585, NDCG@10:0.05190097540616989, NDCG@50:0.08220375329256058\n04/23/2024 04:38:34 - INFO - trainer.finetune_trainer - ***** Saving model checkpoint 23 to ./weights/finetune-Beauty-8192batch\nTraining epoch 24, steps 128 : 100%|██████████| 129/129 [01:53<00:00,  1.14it/s]\n04/23/2024 04:40:28 - INFO - trainer.finetune_evaluator - ***** Run eval *****\n22it [00:04,  4.41it/s]\n04/23/2024 04:40:33 - INFO - trainer.finetune_evaluator - Epoch 24 Eval Result: R@10:0.10597862303256989, R@50:0.24558421969413757, NDCG@10:0.05190502852201462, NDCG@50:0.0822526291012764\nTraining epoch 25, steps 128 : 100%|██████████| 129/129 [01:52<00:00,  1.14it/s]\n04/23/2024 04:42:26 - INFO - trainer.finetune_evaluator - ***** Run eval *****\n22it [00:04,  4.45it/s]\n04/23/2024 04:42:31 - INFO - trainer.finetune_evaluator - Epoch 25 Eval Result: R@10:0.10517372190952301, R@50:0.24495817720890045, NDCG@10:0.051162201911211014, NDCG@50:0.0816599428653717\nTraining epoch 26, steps 128 : 100%|██████████| 129/129 [01:52<00:00,  1.15it/s]\n04/23/2024 04:44:24 - INFO - trainer.finetune_evaluator - ***** Run eval *****\n22it [00:04,  4.40it/s]\n04/23/2024 04:44:30 - INFO - trainer.finetune_evaluator - Epoch 26 Eval Result: R@10:0.10758842527866364, R@50:0.24755175411701202, NDCG@10:0.0517868846654892, NDCG@50:0.08214215189218521\n04/23/2024 04:44:30 - INFO - trainer.finetune_trainer - ***** Saving model checkpoint 26 to ./weights/finetune-Beauty-8192batch\nTraining epoch 27, steps 128 : 100%|██████████| 129/129 [01:52<00:00,  1.14it/s]\n04/23/2024 04:46:23 - INFO - trainer.finetune_evaluator - ***** Run eval *****\n22it [00:04,  4.50it/s]\n04/23/2024 04:46:28 - INFO - trainer.finetune_evaluator - Epoch 27 Eval Result: R@10:0.10544202476739883, R@50:0.24840137362480164, NDCG@10:0.051203515380620956, NDCG@50:0.08242862671613693\nTraining epoch 28, steps 128 : 100%|██████████| 129/129 [01:52<00:00,  1.14it/s]\n04/23/2024 04:48:21 - INFO - trainer.finetune_evaluator - ***** Run eval *****\n22it [00:04,  4.43it/s]\n04/23/2024 04:48:26 - INFO - trainer.finetune_evaluator - Epoch 28 Eval Result: R@10:0.10888520628213882, R@50:0.24934042990207672, NDCG@10:0.052579138427972794, NDCG@50:0.08314532041549683\n04/23/2024 04:48:26 - INFO - trainer.finetune_trainer - ***** Saving model checkpoint 28 to ./weights/finetune-Beauty-8192batch\nTraining epoch 29, steps 128 : 100%|██████████| 129/129 [01:52<00:00,  1.14it/s]\n04/23/2024 04:50:19 - INFO - trainer.finetune_evaluator - ***** Run eval *****\n22it [00:05,  3.96it/s]\n04/23/2024 04:50:25 - INFO - trainer.finetune_evaluator - Epoch 29 Eval Result: R@10:0.10799087584018707, R@50:0.2499217391014099, NDCG@10:0.053445883095264435, NDCG@50:0.08432731032371521\nTraining epoch 30, steps 128 : 100%|██████████| 129/129 [01:52<00:00,  1.14it/s]\n04/23/2024 04:52:18 - INFO - trainer.finetune_evaluator - ***** Run eval *****\n22it [00:05,  3.89it/s]\n04/23/2024 04:52:24 - INFO - trainer.finetune_evaluator - Epoch 30 Eval Result: R@10:0.1046818345785141, R@50:0.24607610702514648, NDCG@10:0.05126892030239105, NDCG@50:0.08205591887235641\nTraining epoch 31, steps 128 : 100%|██████████| 129/129 [01:52<00:00,  1.14it/s]\n04/23/2024 04:54:17 - INFO - trainer.finetune_evaluator - ***** Run eval *****\n22it [00:04,  4.49it/s]\n04/23/2024 04:54:22 - INFO - trainer.finetune_evaluator - Epoch 31 Eval Result: R@10:0.10906407982110977, R@50:0.24817778170108795, NDCG@10:0.052504971623420715, NDCG@50:0.082746222615242\n04/23/2024 04:54:22 - INFO - trainer.finetune_trainer - ***** Saving model checkpoint 31 to ./weights/finetune-Beauty-8192batch\nTraining epoch 32, steps 128 : 100%|██████████| 129/129 [01:52<00:00,  1.15it/s]\n04/23/2024 04:56:15 - INFO - trainer.finetune_evaluator - ***** Run eval *****\n22it [00:04,  4.44it/s]\n04/23/2024 04:56:21 - INFO - trainer.finetune_evaluator - Epoch 32 Eval Result: R@10:0.10678352415561676, R@50:0.2492062747478485, NDCG@10:0.05306803435087204, NDCG@50:0.08411368727684021\nTraining epoch 33, steps 128 : 100%|██████████| 129/129 [01:52<00:00,  1.14it/s]\n04/23/2024 04:58:14 - INFO - trainer.finetune_evaluator - ***** Run eval *****\n22it [00:05,  4.36it/s]\n04/23/2024 04:58:19 - INFO - trainer.finetune_evaluator - Epoch 33 Eval Result: R@10:0.10857219249010086, R@50:0.2505030632019043, NDCG@10:0.05212804675102234, NDCG@50:0.08296003192663193\nTraining epoch 34, steps 128 : 100%|██████████| 129/129 [01:52<00:00,  1.14it/s]\n04/23/2024 05:00:12 - INFO - trainer.finetune_evaluator - ***** Run eval *****\n22it [00:04,  4.44it/s]\n04/23/2024 05:00:17 - INFO - trainer.finetune_evaluator - Epoch 34 Eval Result: R@10:0.10884049534797668, R@50:0.24795420467853546, NDCG@10:0.05289289727807045, NDCG@50:0.08312349021434784\nTraining epoch 35, steps 128 : 100%|██████████| 129/129 [01:53<00:00,  1.14it/s]\n04/23/2024 05:02:11 - INFO - trainer.finetune_evaluator - ***** Run eval *****\n22it [00:05,  4.04it/s]\n04/23/2024 05:02:17 - INFO - trainer.finetune_evaluator - Epoch 35 Eval Result: R@10:0.10946653038263321, R@50:0.24786476790905, NDCG@10:0.05316035449504852, NDCG@50:0.08333021402359009\n04/23/2024 05:02:17 - INFO - trainer.finetune_trainer - ***** Saving model checkpoint 35 to ./weights/finetune-Beauty-8192batch\nTraining epoch 36, steps 128 : 100%|██████████| 129/129 [01:53<00:00,  1.14it/s]\n04/23/2024 05:04:11 - INFO - trainer.finetune_evaluator - ***** Run eval *****\n22it [00:05,  3.84it/s]\n04/23/2024 05:04:17 - INFO - trainer.finetune_evaluator - Epoch 36 Eval Result: R@10:0.10986898094415665, R@50:0.25139740109443665, NDCG@10:0.053540464490652084, NDCG@50:0.08437324315309525\n04/23/2024 05:04:17 - INFO - trainer.finetune_trainer - ***** Saving model checkpoint 36 to ./weights/finetune-Beauty-8192batch\nTraining epoch 37, steps 128 : 100%|██████████| 129/129 [01:53<00:00,  1.14it/s]\n04/23/2024 05:06:10 - INFO - trainer.finetune_evaluator - ***** Run eval *****\n22it [00:04,  4.42it/s]\n04/23/2024 05:06:16 - INFO - trainer.finetune_evaluator - Epoch 37 Eval Result: R@10:0.10803559422492981, R@50:0.24826721847057343, NDCG@10:0.05313226208090782, NDCG@50:0.08372874557971954\nTraining epoch 38, steps 128 : 100%|██████████| 129/129 [01:52<00:00,  1.15it/s]\n04/23/2024 05:08:09 - INFO - trainer.finetune_evaluator - ***** Run eval *****\n22it [00:04,  4.47it/s]\n04/23/2024 05:08:14 - INFO - trainer.finetune_evaluator - Epoch 38 Eval Result: R@10:0.10834860801696777, R@50:0.24983230233192444, NDCG@10:0.05254602059721947, NDCG@50:0.08348847180604935\nTraining epoch 39, steps 128 : 100%|██████████| 129/129 [01:52<00:00,  1.15it/s]\n04/23/2024 05:10:07 - INFO - trainer.finetune_evaluator - ***** Run eval *****\n22it [00:05,  4.39it/s]\n04/23/2024 05:10:12 - INFO - trainer.finetune_evaluator - Epoch 39 Eval Result: R@10:0.10870634019374847, R@50:0.2514421045780182, NDCG@10:0.05304735153913498, NDCG@50:0.08415991067886353\nTraining epoch 40, steps 128 : 100%|██████████| 129/129 [01:52<00:00,  1.15it/s]\n04/23/2024 05:12:05 - INFO - trainer.finetune_evaluator - ***** Run eval *****\n22it [00:04,  4.41it/s]\n04/23/2024 05:12:10 - INFO - trainer.finetune_evaluator - Epoch 40 Eval Result: R@10:0.10736484080553055, R@50:0.24679157137870789, NDCG@10:0.052660007029771805, NDCG@50:0.08304495364427567\nTraining epoch 41, steps 128 : 100%|██████████| 129/129 [01:52<00:00,  1.15it/s]\n04/23/2024 05:14:03 - INFO - trainer.finetune_evaluator - ***** Run eval *****\n22it [00:04,  4.43it/s]\n04/23/2024 05:14:08 - INFO - trainer.finetune_evaluator - Epoch 41 Eval Result: R@10:0.10749898850917816, R@50:0.24911683797836304, NDCG@10:0.05224609375, NDCG@50:0.08319644629955292\nTraining epoch 42, steps 128 : 100%|██████████| 129/129 [01:52<00:00,  1.15it/s]\n04/23/2024 05:16:01 - INFO - trainer.finetune_evaluator - ***** Run eval *****\n22it [00:04,  4.46it/s]\n04/23/2024 05:16:06 - INFO - trainer.finetune_evaluator - Epoch 42 Eval Result: R@10:0.10745427757501602, R@50:0.24934042990207672, NDCG@10:0.052631817758083344, NDCG@50:0.08355852961540222\nTraining epoch 43, steps 128 : 100%|██████████| 129/129 [01:52<00:00,  1.15it/s]\n04/23/2024 05:17:59 - INFO - trainer.finetune_evaluator - ***** Run eval *****\n22it [00:04,  4.44it/s]\n04/23/2024 05:18:05 - INFO - trainer.finetune_evaluator - Epoch 43 Eval Result: R@10:0.10785672813653946, R@50:0.25130796432495117, NDCG@10:0.05288750305771828, NDCG@50:0.08415261656045914\nTraining epoch 44, steps 128 : 100%|██████████| 129/129 [01:52<00:00,  1.15it/s]\n04/23/2024 05:19:58 - INFO - trainer.finetune_evaluator - ***** Run eval *****\n22it [00:04,  4.46it/s]\n04/23/2024 05:20:03 - INFO - trainer.finetune_evaluator - Epoch 44 Eval Result: R@10:0.11116576194763184, R@50:0.2502347528934479, NDCG@10:0.05425189808011055, NDCG@50:0.08445777744054794\n04/23/2024 05:20:03 - INFO - trainer.finetune_trainer - ***** Saving model checkpoint 44 to ./weights/finetune-Beauty-8192batch\nTraining epoch 45, steps 128 : 100%|██████████| 129/129 [01:52<00:00,  1.15it/s]\n04/23/2024 05:21:56 - INFO - trainer.finetune_evaluator - ***** Run eval *****\n22it [00:04,  4.49it/s]\n04/23/2024 05:22:01 - INFO - trainer.finetune_evaluator - Epoch 45 Eval Result: R@10:0.10946653038263321, R@50:0.25081607699394226, NDCG@10:0.053151972591876984, NDCG@50:0.0838899090886116\nTraining epoch 46, steps 128 : 100%|██████████| 129/129 [01:52<00:00,  1.15it/s]\n04/23/2024 05:23:54 - INFO - trainer.finetune_evaluator - ***** Run eval *****\n22it [00:04,  4.42it/s]\n04/23/2024 05:23:59 - INFO - trainer.finetune_evaluator - Epoch 46 Eval Result: R@10:0.1086169108748436, R@50:0.24947457015514374, NDCG@10:0.05271073803305626, NDCG@50:0.0832820013165474\nTraining epoch 47, steps 128 : 100%|██████████| 129/129 [01:52<00:00,  1.15it/s]\n04/23/2024 05:25:52 - INFO - trainer.finetune_evaluator - ***** Run eval *****\n22it [00:04,  4.43it/s]\n04/23/2024 05:25:57 - INFO - trainer.finetune_evaluator - Epoch 47 Eval Result: R@10:0.1089746430516243, R@50:0.2520234286785126, NDCG@10:0.05382655933499336, NDCG@50:0.08517802506685257\nTraining epoch 48, steps 128 : 100%|██████████| 129/129 [01:52<00:00,  1.15it/s]\n04/23/2024 05:27:50 - INFO - trainer.finetune_evaluator - ***** Run eval *****\n22it [00:04,  4.47it/s]\n04/23/2024 05:27:55 - INFO - trainer.finetune_evaluator - Epoch 48 Eval Result: R@10:0.10848275572061539, R@50:0.24951928853988647, NDCG@10:0.052559852600097656, NDCG@50:0.08340387046337128\nTraining epoch 49, steps 128 : 100%|██████████| 129/129 [01:52<00:00,  1.15it/s]\n04/23/2024 05:29:48 - INFO - trainer.finetune_evaluator - ***** Run eval *****\n22it [00:04,  4.48it/s]\n04/23/2024 05:29:53 - INFO - trainer.finetune_evaluator - Epoch 49 Eval Result: R@10:0.10955595970153809, R@50:0.24934042990207672, NDCG@10:0.053715504705905914, NDCG@50:0.08418133854866028\nTraining epoch 50, steps 128 : 100%|██████████| 129/129 [01:52<00:00,  1.15it/s]\n04/23/2024 05:31:46 - INFO - trainer.finetune_evaluator - ***** Run eval *****\n22it [00:04,  4.47it/s]\n04/23/2024 05:31:51 - INFO - trainer.finetune_evaluator - Epoch 50 Eval Result: R@10:0.10816974192857742, R@50:0.24974288046360016, NDCG@10:0.05299479886889458, NDCG@50:0.0838540717959404\nTraining epoch 51, steps 128 : 100%|██████████| 129/129 [01:52<00:00,  1.15it/s]\n04/23/2024 05:33:44 - INFO - trainer.finetune_evaluator - ***** Run eval *****\n22it [00:04,  4.48it/s]\n04/23/2024 05:33:49 - INFO - trainer.finetune_evaluator - Epoch 51 Eval Result: R@10:0.10714125633239746, R@50:0.24880382418632507, NDCG@10:0.05297059938311577, NDCG@50:0.08384966850280762\nTraining epoch 52, steps 128 : 100%|██████████| 129/129 [01:52<00:00,  1.15it/s]\n04/23/2024 05:35:42 - INFO - trainer.finetune_evaluator - ***** Run eval *****\n22it [00:04,  4.46it/s]\n04/23/2024 05:35:47 - INFO - trainer.finetune_evaluator - Epoch 52 Eval Result: R@10:0.11143406480550766, R@50:0.2504136264324188, NDCG@10:0.05488840863108635, NDCG@50:0.08513634651899338\n04/23/2024 05:35:47 - INFO - trainer.finetune_trainer - ***** Saving model checkpoint 52 to ./weights/finetune-Beauty-8192batch\nTraining epoch 53, steps 128 : 100%|██████████| 129/129 [01:52<00:00,  1.15it/s]\n04/23/2024 05:37:40 - INFO - trainer.finetune_evaluator - ***** Run eval *****\n22it [00:04,  4.48it/s]\n04/23/2024 05:37:45 - INFO - trainer.finetune_evaluator - Epoch 53 Eval Result: R@10:0.10973482578992844, R@50:0.25081607699394226, NDCG@10:0.054078780114650726, NDCG@50:0.08490681648254395\nTraining epoch 54, steps 128 : 100%|██████████| 129/129 [01:52<00:00,  1.15it/s]\n04/23/2024 05:39:38 - INFO - trainer.finetune_evaluator - ***** Run eval *****\n22it [00:04,  4.44it/s]\n04/23/2024 05:39:43 - INFO - trainer.finetune_evaluator - Epoch 54 Eval Result: R@10:0.10946653038263321, R@50:0.2488485425710678, NDCG@10:0.053555313497781754, NDCG@50:0.08395237475633621\nTraining epoch 55, steps 128 : 100%|██████████| 129/129 [01:52<00:00,  1.15it/s]\n04/23/2024 05:41:36 - INFO - trainer.finetune_evaluator - ***** Run eval *****\n22it [00:04,  4.43it/s]\n04/23/2024 05:41:41 - INFO - trainer.finetune_evaluator - Epoch 55 Eval Result: R@10:0.11013727635145187, R@50:0.2495640069246292, NDCG@10:0.053706493228673935, NDCG@50:0.08413713425397873\nTraining epoch 56, steps 128 : 100%|██████████| 129/129 [01:52<00:00,  1.15it/s]\n04/23/2024 05:43:34 - INFO - trainer.finetune_evaluator - ***** Run eval *****\n22it [00:04,  4.45it/s]\n04/23/2024 05:43:39 - INFO - trainer.finetune_evaluator - Epoch 56 Eval Result: R@10:0.10821446031332016, R@50:0.24916155636310577, NDCG@10:0.052981991320848465, NDCG@50:0.08379320055246353\nTraining epoch 57, steps 128 : 100%|██████████| 129/129 [01:52<00:00,  1.14it/s]\n04/23/2024 05:45:33 - INFO - trainer.finetune_evaluator - ***** Run eval *****\n22it [00:04,  4.45it/s]\n04/23/2024 05:45:38 - INFO - trainer.finetune_evaluator - Epoch 57 Eval Result: R@10:0.11080802977085114, R@50:0.2508607804775238, NDCG@10:0.05403095483779907, NDCG@50:0.08459825068712234\nTraining epoch 58, steps 128 : 100%|██████████| 129/129 [01:52<00:00,  1.15it/s]\n04/23/2024 05:47:31 - INFO - trainer.finetune_evaluator - ***** Run eval *****\n22it [00:04,  4.41it/s]\n04/23/2024 05:47:36 - INFO - trainer.finetune_evaluator - Epoch 58 Eval Result: R@10:0.10951124131679535, R@50:0.2537226676940918, NDCG@10:0.05275373160839081, NDCG@50:0.0842631533741951\nTraining epoch 59, steps 128 : 100%|██████████| 129/129 [01:52<00:00,  1.15it/s]\n04/23/2024 05:49:29 - INFO - trainer.finetune_evaluator - ***** Run eval *****\n22it [00:04,  4.47it/s]\n04/23/2024 05:49:34 - INFO - trainer.finetune_evaluator - Epoch 59 Eval Result: R@10:0.11062916368246078, R@50:0.2520234286785126, NDCG@10:0.054124899208545685, NDCG@50:0.0849691852927208\nTraining epoch 60, steps 128 : 100%|██████████| 129/129 [01:52<00:00,  1.15it/s]\n04/23/2024 05:51:27 - INFO - trainer.finetune_evaluator - ***** Run eval *****\n22it [00:04,  4.41it/s]\n04/23/2024 05:51:32 - INFO - trainer.finetune_evaluator - Epoch 60 Eval Result: R@10:0.110047847032547, R@50:0.2492062747478485, NDCG@10:0.053321726620197296, NDCG@50:0.08365392684936523\nTraining epoch 61, steps 128 : 100%|██████████| 129/129 [01:52<00:00,  1.15it/s]\n04/23/2024 05:53:25 - INFO - trainer.finetune_evaluator - ***** Run eval *****\n22it [00:04,  4.44it/s]\n04/23/2024 05:53:30 - INFO - trainer.finetune_evaluator - Epoch 61 Eval Result: R@10:0.11058444529771805, R@50:0.24831193685531616, NDCG@10:0.053247906267642975, NDCG@50:0.08319153636693954\nTraining epoch 62, steps 128 : 100%|██████████| 129/129 [01:52<00:00,  1.15it/s]\n04/23/2024 05:55:23 - INFO - trainer.finetune_evaluator - ***** Run eval *****\n22it [00:04,  4.40it/s]\n04/23/2024 05:55:28 - INFO - trainer.finetune_evaluator - Epoch 62 Eval Result: R@10:0.11107632517814636, R@50:0.2515762448310852, NDCG@10:0.053877923637628555, NDCG@50:0.08450689911842346\n04/23/2024 05:55:28 - INFO - trainer.finetune_trainer - ***** Resume Model from path ./weights/finetune-Beauty-8192batch\n04/23/2024 05:55:28 - INFO - trainer.finetune_evaluator - ***** Run test *****\n22it [00:04,  4.46it/s]\n04/23/2024 05:55:34 - INFO - trainer.finetune_evaluator - Test Result: R@10:0.09690112620592117, R@50:0.2327505201101303, NDCG@10:0.047877319157123566, NDCG@50:0.07760857045650482\n","output_type":"stream"}]}]}